---
title: "Diff-in-Diff 1: Simple DiD"
author: "Matt Birch"
date: "2023-02-25"
output: html_document
---

# Intro to Difference in Differences
### This one will be the simple version. More exciting videos to come!

```{r, message = FALSE, warning = FALSE}
rm(list = ls())
library(ggplot2)
library(stargazer)
```

The best approach to estimating causal impacts is with a randomized trial, such as with an A/B test. In many cases, however, randomization is either unfeasible or unethical, or both. Sometimes the real world conducts natural experiments, in which some people receive treatment while others do not. With careful analysis, we can exploit these natural experiments to identify the causal relationship. 

One of the most common methods is Difference in Differences, also called diff-in-diff or DiD. DiD is an empirical technique to exploit natural experiments to identify causal relationships. The general idea is that the data is separated into treatment and control groups, without us running a real experiment. Under certain assumptions, we can compare the treatment and control groups (one difference) before and after treatment occurs (another difference). We can see how the difference between groups changes, and find our causal effect. 

So let's get some [fake] data!

```{r}
stem_data <- read.csv("https://raw.githubusercontent.com/MattBirch42/Causal-Inference-Stuff/main/vanilla_did.csv")
```

```{r, echo = FALSE, }
#setting up variables to be used throughout. If I update the data generation, fix this first.
stem2 <- stem_data
tgroup <- 'regions 2 and 4'
cutoff <- 2015
min_year <- min(stem2$year)
max_year <- max(stem2$year)
```

### Explanation of Data
This is fake data about an imagined scenario that I used for a class assignment. The STEM program gives students in the participating region extra training in math and science. Not all regions participate. We will compare the test scores of students in participating regions those who are not before and after the program is implemented. In this data, `r tgroup` implement the STEM program in `r cutoff` and later. 

Provided Features:

* year = year
* region: These represent some fictional geographic region, 7 regions in all
* score: Assessment exam score (this is our dependent variable)


### Create plot to show the issue
Let's look at average scores in `r tgroup` vs other regions combined.

Before `r cutoff`, `r tgroup` seems to lag behind the rest. Then in `r cutoff`, with the STEM program, scores in `r tgroup` jump to a higher level. You can see that the difference between the groups is different on each side of the cutoff. There is a difference in the differences. With a good DiD, you can *see* the treatment in a graph like this, even before quantifying it. Although it may not be *this* obvious.

```{r, echo = FALSE}
stem2$reg24 = ifelse(stem2$region %in% c(2,4),'Region 2 or 4','Other Regions')

ggplot(stem2, aes(x = year, y = score, color = reg24)) +
  geom_point(size = 1, alpha = 0.1) +
  labs(x = "Year", y = "Average Score", color = "Region") +
  scale_color_manual(values = c("blue", "red")) +
  theme_light() +
  geom_vline(xintercept = (cutoff-0.5), linetype = "dashed") +
  scale_x_continuous(breaks = seq(min_year,max_year, by = 1))
```

It may be instructive to just look at the average score for each year, instead.

```{r, echo = FALSE}
avg_scores <- aggregate(score ~ reg24 + year, data = stem2, FUN = mean)

ggplot(avg_scores, aes(x = year, y = score, color = reg24)) +
  geom_point(size = 3) +
  labs(x = "Year", y = "Average Score", color = "Region") +
  scale_color_manual(values = c("blue", "red")) +
  theme_light() +
  geom_vline(xintercept = (cutoff-0.5), linetype = "dashed") +
  scale_x_continuous(breaks = seq(min_year,max_year, by = 1))

```

Either way works. However, eyeballing the graph is not enough. We still have to talk about the model assumptions, as well as estimation and inference. 

### Main Assumption
To successfully execute DiD and trust the results as a causal effect, you have to assume that the trends between treatment and control are parallel before and after the treatment. In this case, the trends (slopes) do seem similar, before and after. 

### Execution
To perform the most basic version of a DiD, you use a regression with at least 3 variables. You must have:

* a treatment group variable that determines whether a group is ever treated
* a treatment time variable that says whether treatment is occurring anywhere (doesn't actually have to be time)
* an interaction term that marks whether a sample is in the treatment group AND ALSO currently being treated.

You can add additional covariates, but these 3 are the required components.

Treatment group:
``` {r}
stem2$r24<-ifelse(stem2$region %in% c(2,4),1,0)
```

Treatment time:
``` {r}
stem2$y2015plus<-ifelse(stem2$year>=cutoff,1,0)
```

Interaction, both group and time:
``` {r}
stem2$r24_2015<-stem2$r24*stem2$y2015plus
```

And the actual regression: 
``` {r}
dd_reg1 <- lm(score ~ r24_2015 + r24 + y2015plus, data = stem2)
dd_reg1$coefficients
```

That is the simplest version possible, but it is not the best model possible. We'll do a better one in a minute. The graph below shows what the regression predicts for treatment and control groups. Note that the gap between the treatment and control groups on the left is much wider, and the gap on the right is much narrower. There is a difference in the differences. The decrease in the gap is our treatment effect, and is the coefficient on the interaction term `r24_2015`, which is about a `r round(dd_reg1$coefficients[2],0)` point gain from the stem program.

```{r, echo = FALSE}

ggplot(avg_scores, aes(x = year, y = score, color = reg24)) +
  geom_point(size = 3) +
  labs(x = "Year", y = "Average Score", color = "Region") +
  scale_color_manual(values = c("blue", "red")) +
  theme_light()+
  geom_vline(xintercept = (cutoff-0.5), linetype = "dashed") +
  scale_x_continuous(breaks = seq(min_year,max_year, by = 1)) + 
  # control
  geom_segment (aes (x=min_year,
                     xend=(cutoff-1),
                     y=dd_reg1$coefficients[1],
                     yend=dd_reg1$coefficients[1]), 
                color = "blue") + 
  geom_segment (aes (x=cutoff,
                     xend=max_year,
                     y=dd_reg1$coefficients[1]+dd_reg1$coefficients[4],
                     yend=dd_reg1$coefficients[1]+dd_reg1$coefficients[4]), 
                color = "blue") +
  # treatment
  geom_segment (aes (x=min_year,
                     xend=(cutoff-1),
                     y=dd_reg1$coefficients[1]+dd_reg1$coefficients[3],
                     yend=dd_reg1$coefficients[1]+dd_reg1$coefficients[3]), 
                color = "red") + 
  geom_segment (aes (x=cutoff,
                     xend=max_year,
                     y=dd_reg1$coefficients[1]+dd_reg1$coefficients[2]+dd_reg1$coefficients[3]+dd_reg1$coefficients[4],
                     yend=dd_reg1$coefficients[1]+dd_reg1$coefficients[2]+dd_reg1$coefficients[3]+dd_reg1$coefficients[4]), 
                color = "red")

```


However, the dummy variable time trend leads to underwhelming results! We can make the model more flexible. Looking at our plot, it is clear that there is a gradual time trend throughout the years, rather than a discrete jump. Consequently, we may want to adjust our model to account for that. Here is a new version of the regression that includes a gradual time trend rather than a discrete one. 

``` {r}
stem2$year_centered <- stem2$year - min_year

dd_reg2 <- lm(score ~ r24_2015 + r24 + year_centered, data = stem2)
dd_reg2$coefficients
```

This model still has the time trend, the difference between treatment and control, and the interaction term that specifies that the treatment group is being treated. We have just modified the time trend. 

We interpret these coefficients separately, but only the coefficient on the interaction is about the actual causal effect from the STEM treatment. 

The intercept tells us that the baseline score in this data set (the control regions) is `r round(dd_reg2$coefficients[1],0)`.

The `r24` coefficient tells us that in the beginning, `r tgroup` had scores `r abs(round(dd_reg2$coefficients[3],0))` points `r ifelse(dd_reg2$coefficients[3]<0,'below','above')` the baseline of the other regions.

The coefficient on the time variable `year` says that across regions, `score` was `r ifelse(dd_reg2$coefficients[3]<0,'decreasing','increasing')` by `r abs(round(dd_reg2$coefficients[4],0))` points annually.

We have accounted for regions and time trends. Now we use the interaction to see if there is a difference in the regional differences before and after the time change. The coefficient on `r2_2015`, `r round(dd_reg2$coefficients[2],2)` tells us that students in `r tgroup` increased their scores by `r round(dd_reg2$coefficients[2],2)` points more than the other groups. The difference between groups changed by that much. *This would be the causal effect of the STEM program.* This is how many points the treatment group gains above and beyond the shared time trend. 

Here is the regression graph. Better, eh?

```{r, echo = FALSE}

ggplot(avg_scores, aes(x = year, y = score, color = reg24)) +
  geom_point(size = 3) +
  labs(x = "Year", y = "Average Score", color = "Region") +
  scale_color_manual(values = c("blue", "red")) +
  theme_light()+
  geom_vline(xintercept = (cutoff-0.5), linetype = "dashed") +
  scale_x_continuous(breaks = seq(min_year,max_year, by = 1)) + 
  # control
  geom_segment (aes (x=min_year,
                     xend=(cutoff-1),
                     y=dd_reg2$coefficients[1],
                     yend=dd_reg2$coefficients[1] + (cutoff-1-min_year)*dd_reg2$coefficients[4]), 
                color = "blue") + 
  geom_segment (aes (x=cutoff,
                     xend=max_year,
                     y=dd_reg2$coefficients[1] + (cutoff-min_year)*dd_reg2$coefficients[4]),
                     yend=dd_reg2$coefficients[1]+(max_year - min_year)*dd_reg2$coefficients[4],
                color = "blue") +
  # treatment
  geom_segment (aes (x=min_year,
                     xend=(cutoff-1),
                     y=dd_reg2$coefficients[1] + dd_reg2$coefficients[3],
                     yend=dd_reg2$coefficients[1]  + dd_reg2$coefficients[3] + (cutoff-1-min_year)*dd_reg2$coefficients[4]), 
                color = "red") + 
  geom_segment (aes (x=cutoff,
                     xend=max_year,
                     y=dd_reg2$coefficients[1] + dd_reg2$coefficients[2]+ dd_reg2$coefficients[3]+ (cutoff-min_year)*dd_reg2$coefficients[4]),
                     yend=dd_reg2$coefficients[1]+ dd_reg1$coefficients[2]+ dd_reg2$coefficients[3] +(max_year - min_year)*dd_reg2$coefficients[4],
                color = "red")
```

Ironically, both models give very similar results. The treatment effect in the first model with the discrete time trend is `r round(dd_reg1$coefficients[2],2)`, while the treatment effect with the linear time trend is `r round(dd_reg2$coefficients[2],2)`. It won't always be so clean. This is fake data.

### Summarizing what we have so far:

The data displays parallel trends for treatment and control groups over time. We can see it. These parallel trends and the existence of a treatment for one group and not the other means we can use difference in differences. To do this, we implement a regression that controls for the initial gap between groups (treatment group dummy), accounts for the common time trend, and includes an interaction term that shows whether or not the treatment group is currently being treated. This last interaction term is the causal treatment effect, assuming we believe the parallel trends assumption. It shows how much the gap between treatment and control changes over the cutoff. It may be worth your while to see how I built that last graph to demonstrate to yourself that the coefficient on the interaction term is equal to the discrete change in the gaps. 

Note that we can include more features in the model if we want to. In some cases, trends are not parallel until you control for other observable characteristics, so they become necessary.

### What have we not covered yet?

We have talked about the point estimates from the regressions. We have not discussed statistical significance or inference at all. Unfortunately, we cannot use the standard output from the linear regression model. The standard errors there assume every observation is independent and identically distributed, but that is not true in this panel data set. 

### Inference
