---
title: "Diff-in-Diff 1: Simple DiD"
author: "Matt Birch"
date: "2023-02-25"
output: html_document
---

# Intro to Difference in Differences
## Part 1 (of 4): Vanilla DiD

Video link: 

This section introduces Difference in Difference estimation in its simplest form. In future sections and videos, I intend to expand on this with synthetic controls (2), multiple treatment times (3), and higher order differences (4) such as difference in difference in differences. You don't even know what any of that means yet, but you will!

The best approach to estimating causal impacts is with a randomized trials, such as with an A/B test. In many cases, however, randomization is either unfeasible or unethical, or both. Sometimes the real world conducts natural experiments, in which some people receive treatment while others do not. With careful analysis, we can exploit these natural experiments to identify the causal relationship. 

One of the most common methods is Difference in Differences, also called diff-in-diff or DiD. DiD is an empirical technique to exploit natural experiments to identify causal relationships. The general idea is that the data is separated into treatment and control groups, without us running a real experiment. Under certain assumptions, we can compare the treatment and control groups (one difference) before and after treatment occurs (another difference). We can see how the difference between groups changes, and find our causal effect. 

Necessary libraries:
```{r, message = FALSE, warning = FALSE}
                   # none needed for DiD point estimates
library(ggplot2)   # for visualizations
library(sandwich)  # to get fancy covariance matrix
library(lmtest)    # to attach fancy covariance matrix to DiD estimates
```

So let's get some [fake] data!

```{r}
stem_data <- read.csv("https://raw.githubusercontent.com/MattBirch42/Causal-Inference-Stuff/main/vanilla_did.csv")
```

```{r, echo = FALSE, }
#setting up variables to be used throughout. If I update the data generation, fix this first.
stem2 <- stem_data
tgroup <- 'regions 2 and 4'
cutoff <- 2015
min_year <- min(stem2$year)
max_year <- max(stem2$year)
```

### Explanation of Data
This is fake data about an imagined scenario that I used for a class assignment. The STEM program gives students in the participating region extra training in math and science. Not all regions participate. We will compare the test scores of students in participating regions those who are not before and after the program is implemented. In this data, `r tgroup` implement the STEM program in `r cutoff` and later. 

Provided Features:

* year = year
* region: These represent some fictional geographic region, 7 regions in all
* score: Assessment exam score (this is our dependent variable)


### Create plot to show the issue

Before `r cutoff`, `r tgroup` seems to lag behind the rest. Then in `r cutoff`, with the STEM program, scores in `r tgroup` jump to a higher level. You can see that the difference between the groups is different on each side of the cutoff. There is a difference in the differences. This is the image of a 'natural experiment' at work. The world, outside of a laboratory, created a treatment and control group and gave out treatment. We want to use that. With a good DiD, you can *see* the treatment in a graph like this, even before quantifying it. Although it will basically never be *this* obvious.

```{r, echo = FALSE}
stem2$reg24 = ifelse(stem2$region %in% c(2,4),'Region 2 or 4','Other Regions')

ggplot(stem2, aes(x = year, y = score, color = reg24)) +
  geom_point(size = 1, alpha = 0.1) +
  labs(x = "Year", y = "Average Score", color = "Region") +
  scale_color_manual(values = c("blue", "red")) +
  theme_light() +
  geom_vline(xintercept = (cutoff-0.5), linetype = "dashed") +
  scale_x_continuous(breaks = seq(min_year,max_year, by = 1))
```

It may be instructive to just look at the average score for each year, instead.

```{r, echo = FALSE}
avg_scores <- aggregate(score ~ reg24 + year, data = stem2, FUN = mean)

ggplot(avg_scores, aes(x = year, y = score, color = reg24)) +
  geom_point(size = 3) +
  labs(x = "Year", y = "Average Score", color = "Region") +
  scale_color_manual(values = c("blue", "red")) +
  theme_light() +
  geom_vline(xintercept = (cutoff-0.5), linetype = "dashed") +
  scale_x_continuous(breaks = seq(min_year,max_year, by = 1))

```

Either way works. However, eyeballing the graph is not enough. If we want to quantiy the impact of the STEM treatment on the treated regions, we still have to talk about the model assumptions, as well as estimation and inference. 

### Main Assumption
To successfully execute DiD and trust the results as a causal effect, you have to assume that the trends between treatment and control are parallel before and after the treatment. In this case, the trends (slopes) do seem similar, before and after. 

### Execution
To perform the most basic version of a DiD, you use a regression with at least 3 variables. You must have:

* a treatment group variable that determines whether a group is ever treated
* a treatment time variable that says whether treatment is occurring anywhere (doesn't actually have to be time)
* an interaction term that marks whether a sample is in the treatment group AND ALSO currently being treated.

You can add additional covariates, but these 3 are the required components.

Treatment group:
``` {r}
stem2$r24<-ifelse(stem2$region %in% c(2,4),1,0)
```

Treatment time:
``` {r}
stem2$y2015plus<-ifelse(stem2$year>=cutoff,1,0)
```

Interaction, both group and time:
``` {r}
stem2$r24_2015<-stem2$r24*stem2$y2015plus
```

And the actual regression: 
``` {r}
dd_reg1 <- lm(score ~ r24_2015 + r24 + y2015plus, data = stem2)
dd_reg1$coefficients
```

That is the simplest version possible, but it is not the best model possible. We'll do a better one in a minute. The graph below shows what the regression predicts for treatment and control groups. With no slope parameters, it just compares the averages on either side of the cutoff. Note that the gap between the treatment and control groups on the left is much wider, and the gap on the right is much narrower. There is a difference in the differences (see what I did there?). The decrease in the gap is our treatment effect, and is the coefficient on the interaction term `r24_2015`, which is about a `r round(dd_reg1$coefficients[2],0)` point gain from the stem program. That is how many points those students 'caught up' by. 

```{r, echo = FALSE}

ggplot(avg_scores, aes(x = year, y = score, color = reg24)) +
  geom_point(size = 3) +
  labs(x = "Year", y = "Average Score", color = "Region") +
  scale_color_manual(values = c("blue", "red")) +
  theme_light()+
  geom_vline(xintercept = (cutoff-0.5), linetype = "dashed") +
  scale_x_continuous(breaks = seq(min_year,max_year, by = 1)) + 
  # control
  geom_segment (aes (x=min_year,
                     xend=(cutoff-1),
                     y=dd_reg1$coefficients[1],
                     yend=dd_reg1$coefficients[1]), 
                color = "blue") + 
  geom_segment (aes (x=cutoff,
                     xend=max_year,
                     y=dd_reg1$coefficients[1]+dd_reg1$coefficients[4],
                     yend=dd_reg1$coefficients[1]+dd_reg1$coefficients[4]), 
                color = "blue") +
  # treatment
  geom_segment (aes (x=min_year,
                     xend=(cutoff-1),
                     y=dd_reg1$coefficients[1]+dd_reg1$coefficients[3],
                     yend=dd_reg1$coefficients[1]+dd_reg1$coefficients[3]), 
                color = "red") + 
  geom_segment (aes (x=cutoff,
                     xend=max_year,
                     y=dd_reg1$coefficients[1]+dd_reg1$coefficients[2]+dd_reg1$coefficients[3]+dd_reg1$coefficients[4],
                     yend=dd_reg1$coefficients[1]+dd_reg1$coefficients[2]+dd_reg1$coefficients[3]+dd_reg1$coefficients[4]), 
                color = "red")

```


However, the dummy variable time trend leads to underwhelming results! We can make the model more flexible. Looking at our plot, it is clear that there is a gradual time trend throughout the years, rather than a discrete jump. Consequently, we may want to adjust our model to account for that. Here is a new version of the regression that includes a gradual time trend rather than a discrete one. 

``` {r}
stem2$year_centered <- stem2$year - min_year

dd_reg2 <- lm(score ~ r24_2015 + r24 + year_centered, data = stem2)
dd_reg2$coefficients
```

This model still has the time trend, the difference between treatment and control, and the interaction term that specifies that the treatment group is being treated. We have just modified the time trend. 

We interpret these coefficients separately, but only the coefficient on the interaction is about the actual causal effect from the STEM treatment. 

The intercept tells us that the baseline score in this data set (the control regions) is `r round(dd_reg2$coefficients[1],0)`.

The `r24` coefficient tells us that in the beginning, `r tgroup` had scores `r abs(round(dd_reg2$coefficients[3],0))` points `r ifelse(dd_reg2$coefficients[3]<0,'below','above')` the baseline of the other regions.

The coefficient on the time variable `year` says that across regions, `score` was `r ifelse(dd_reg2$coefficients[3]<0,'decreasing','increasing')` by `r abs(round(dd_reg2$coefficients[4],0))` points annually.

We have accounted for regions and time trends. Now we use the interaction to see if there is a difference in the regional differences before and after the time change. The coefficient on `r2_2015`, `r round(dd_reg2$coefficients[2],2)` tells us that students in `r tgroup` increased their scores by `r round(dd_reg2$coefficients[2],2)` points more than the other groups. The difference between groups changed by that much. *This would be the causal effect of the STEM program.* This is how many points the treatment group gains above and beyond the shared time trend, and we attribute it to STEM (treatment). 

Here is the regression graph. Better, eh?

```{r, echo = FALSE}

ggplot(avg_scores, aes(x = year, y = score, color = reg24)) +
  geom_point(size = 3) +
  labs(x = "Year", y = "Average Score", color = "Region") +
  scale_color_manual(values = c("blue", "red")) +
  theme_light()+
  geom_vline(xintercept = (cutoff-0.5), linetype = "dashed") +
  scale_x_continuous(breaks = seq(min_year,max_year, by = 1)) + 
  # control
  geom_segment (aes (x=min_year,
                     xend=(cutoff-1),
                     y=dd_reg2$coefficients[1],
                     yend=dd_reg2$coefficients[1] + (cutoff-1-min_year)*dd_reg2$coefficients[4]), 
                color = "blue") + 
  geom_segment (aes (x=cutoff,
                     xend=max_year,
                     y=dd_reg2$coefficients[1] + (cutoff-min_year)*dd_reg2$coefficients[4]),
                     yend=dd_reg2$coefficients[1]+(max_year - min_year)*dd_reg2$coefficients[4],
                color = "blue") +
  # treatment
  geom_segment (aes (x=min_year,
                     xend=(cutoff-1),
                     y=dd_reg2$coefficients[1] + dd_reg2$coefficients[3],
                     yend=dd_reg2$coefficients[1]  + dd_reg2$coefficients[3] + (cutoff-1-min_year)*dd_reg2$coefficients[4]), 
                color = "red") + 
  geom_segment (aes (x=cutoff,
                     xend=max_year,
                     y=dd_reg2$coefficients[1] + dd_reg2$coefficients[2]+ dd_reg2$coefficients[3]+ (cutoff-min_year)*dd_reg2$coefficients[4]),
                     yend=dd_reg2$coefficients[1]+ dd_reg1$coefficients[2]+ dd_reg2$coefficients[3] +(max_year - min_year)*dd_reg2$coefficients[4],
                color = "red")
```

Both models give very similar results. The treatment effect in the first model with the discrete time trend is `r round(dd_reg1$coefficients[2],2)`, while the treatment effect with the linear time trend is `r round(dd_reg2$coefficients[2],2)`. It won't always be so clean. This is fake data.

### Summarizing what we have so far:

The data displays parallel trends for treatment and control groups over time. We can see it. These parallel trends and the existence of a treatment for one group and not the other means we can use difference in differences. To do this, we implement a regression that controls for the initial gap between groups (treatment group dummy), accounts for the common time trend, and includes an interaction term that shows whether or not the treatment group is currently being treated. This last interaction term is the causal treatment effect, assuming we believe the parallel trends assumption. It shows how much the gap between treatment and control changes over the cutoff. It may be worth your while to see how I built that last graph to demonstrate to yourself that the coefficient on the interaction term is equal to the discrete change in the gaps. 

Note that we can include more features in the model if we want to. In some cases, trends are not parallel until you control for other observable characteristics, so they become necessary.

### What have we not covered yet?

We have talked about the point estimates from the regressions. We have not discussed statistical significance or inference at all. Unfortunately, we cannot use the standard output from the linear regression model. The standard errors there assume every observation is independent and identically distributed. This often untrue in panel data sets like this one where each region could have its on error distribution or where there is autocorrelation across time.

### Inference

One common approach is to the "different error distribution by region" problem is to cluster your standard errors at the region-year level. This is where the `sandwich` package comes in. Clustering errors at the region-year level allows each region-year to have a different distribution of error terms. We have to start by creating a cluster variable, which in this case means it will take unique values for each region-year combo.

``` {r, results = 'hide'}
stem2$cluster_var <- paste(stem2$region, stem2$year_centered, sep = "-")
```

Then we generate the robust covariance matrix with clustered errors. If you do a lot of regression work with real world data, you should look into other options for the `vcovHC()` function. It is pretty awesome!

```{r}
dd_reg2 <- lm(score ~ r24_2015 + r24 + year_centered, data = stem2)
better_cov <- vcovHC(dd_reg2, type = "HC0", cluster = c("cluster_var"))
```

Recall the original regression:
```{r}
print(summary(dd_reg2))
```

Our updated regression with fancy standard errors:
```{r}
dd_reg2_clustered <-coeftest(dd_reg2, vcov = better_cov)
print(dd_reg2_clustered)
```

The coefficients are the same, and always will be. But the standard errors and p-values will often be quite different from each other. You will notice that the main regression `dd_reg2` and the regression with clustered standard errors `dd_reg2_clustered` are not meaningfully different from each other.

They will be similar if the standard errors are independent across clusters, not just within clusters. In this case, I generated the data with just a few lines of code and everything has the literally same error distribution, so it is no surprise that the regressions are approximately equivalent. In the real world, clustering your errors can make major changes to your standard errors and your p-values, so even though this fictional data set did not need it, I included the process for you. 

**To clarify:** If this were a real data set, I would use the regression coefficients to estimate the treatment effect, but in order to draw inference from them with confidence intervals, I would want to use the clustered standard errors. If we had additional autocorrelation, this would be additionally more complex. 

**Takeaway:** Difference in Differences relies a 'natural experiment,' wherein the real world separates a treatment and control group and doses treatment. If trends are parallel, we can use DiD to exploit the natural experiment to estimate the causal impact of treatment to the average person in the treatment group. This involves a regression with at least 3 specific variables, and it will likely also need special standard errors. 

## Part 2 (of 4): Synthetic Controls
## Part 3 (of 4): Multiple treatment cutoffs
## Part 4 (of 4): Higher orders: DiD, DiDiD, DiDiDiD,...
